{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqeg0NrPvKtsQendUR4xp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunaeee/KU-SW-Academy/blob/main/1004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrtx4HBkWf9e"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "Okt().pos('코로나 극복 이후 해외여행 수요가 늘면서, 소비자 상담과 피해접수 건수도 증가하고 있는 것으로 나타났다.')\n",
        "OpenJDK 64-Bit Server VM warning: Attempt to protect stack guard pages failed.\n",
        "OpenJDK 64-Bit Server VM warning: Attempt to deallocate stack guard pages failed.\n",
        "[('코로나', 'Noun'),\n",
        " ('극복', 'Noun'),\n",
        " ('이후', 'Noun'),\n",
        " ('해외여행', 'Noun'),\n",
        " ('수요', 'Noun'),\n",
        " ('가', 'Josa'),\n",
        " ('늘면서', 'Verb'),\n",
        " (',', 'Punctuation'),\n",
        " ('소비자', 'Noun'),\n",
        " ('상담', 'Noun'),\n",
        " ('과', 'Josa'),\n",
        " ('피해', 'Noun'),\n",
        " ('접수', 'Noun'),\n",
        " ('건', 'Noun'),\n",
        " ('수도', 'Noun'),\n",
        " ('증가', 'Noun'),\n",
        " ('하고', 'Josa'),\n",
        " ('있는', 'Adjective'),\n",
        " ('것', 'Noun'),\n",
        " ('으로', 'Josa'),\n",
        " ('나타났다', 'Verb'),\n",
        " ('.', 'Punctuation')]\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "regexp_tokenize('코로나 극복 이후 해외여행 수요가 늘면서, 소비자 상담과 피해접수 건수도 증가하고 있는 것으로 나타났다.',\n",
        "                r'\\b(\\w+)\\b')\n",
        "['코로나',\n",
        " '극복',\n",
        " '이후',\n",
        " '해외여행',\n",
        " '수요가',\n",
        " '늘면서',\n",
        " '소비자',\n",
        " '상담과',\n",
        " '피해접수',\n",
        " '건수도',\n",
        " '증가하고',\n",
        " '있는',\n",
        " '것으로',\n",
        " '나타났다']\n",
        "KoNLPy 사이트\n",
        "                 (mac) 0. homebrew\n",
        "1. JDK1.8   |    openjdk\n",
        "2. whl(윈도우)       X\n",
        "3. konlpy install\n",
        "\n",
        "경로를 찾을 수 없음 등 => java path 확인\n",
        "whl 설치 불가 => python, os bits 확인\n",
        "실행시키면 뻗음 => whl downgrade\n",
        "from nltk.corpus import gutenberg\n",
        "emma = gutenberg.open(gutenberg.fileids()[0]).read()\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tokenize import regexp_tokenize, TweetTokenizer\n",
        "# PennTreebank => , Stanford(bin)\n",
        "from nltk.help import brown_tagset, upenn_tagset\n",
        "Tokenizing => Morpheme Anlaysis; for Feature(Extraction/Selection)\n",
        "                                 => Data 대표하는 특징\n",
        "                                 => Model Complexity 감소\n",
        "문서(헌) => 여러개 문단 => 여러개 문장\n",
        "가장 작은 단위 문서=문장\n",
        "len(emma.splitlines()), len(sent_tokenize(emma))\n",
        "(16823, 7456)\n",
        "from string import punctuation\n",
        "from nltk import punkt\n",
        "sent_tokenize('''\n",
        "\"아버지가 방에 들어가신다.\"라고 누가 얘기했다.\n",
        "아버지가 방에 들어가셨다\n",
        "''')\n",
        "=> 구두점, 이모티콘X, 인용문X\n",
        "['\\n\"아버지가 방에 들어가신다.', '\"라고 누가 얘기했다.', '아버지가 방에 들어가셨다']\n",
        "word_tokenize('''\n",
        "D.C. I'd like ~ \"아버지가방에들어가신다.\"라고 누가 얘기했다. 아버지가 방에 들어가신다.\n",
        "''',\n",
        "              preserve_line=False)\n",
        "['D.C',\n",
        " '.',\n",
        " 'I',\n",
        " \"'d\",\n",
        " 'like',\n",
        " '~',\n",
        " '``',\n",
        " '아버지가방에들어가신다',\n",
        " '.',\n",
        " '``',\n",
        " '라고',\n",
        " '누가',\n",
        " '얘기했다',\n",
        " '.',\n",
        " '아버지가',\n",
        " '방에',\n",
        " '들어가신다',\n",
        " '.']\n",
        "len(regexp_tokenize(emma, r'\\b[A-Z]\\w+\\b'))\n",
        "15203\n",
        "len(regexp_tokenize(emma, r'\\b\\w+\\b'))\n",
        "161983\n",
        "regexp_tokenize('''\n",
        "\"아버지가 방에 들어가신다.\"라고 누가 얘기했다.\n",
        "아버지가 방에 들어가셨다\n",
        "넘나 슬퍼써 ㅠㅠ :)\n",
        "''', r'[ㅠㅜㅡ:=)(]{2,}')\n",
        "['ㅠㅠ', ':)']\n",
        "TweetTokenizer().tokenize('''\n",
        "\"아버지가 방에 들어가신다.\"라고 누가 얘기했다.\n",
        "아버지가 방에 들어가셨다\n",
        "넘나 슬퍼써 ㅠㅠ :)\n",
        "''')\n",
        "['\"',\n",
        " '아버지가',\n",
        " '방에',\n",
        " '들어가신다',\n",
        " '.',\n",
        " '\"',\n",
        " '라고',\n",
        " '누가',\n",
        " '얘기했다',\n",
        " '.',\n",
        " '아버지가',\n",
        " '방에',\n",
        " '들어가셨다',\n",
        " '넘나',\n",
        " '슬퍼써',\n",
        " 'ㅠㅠ',\n",
        " ':)']\n",
        "구두점 토큰화 - 부족\n",
        "형태소 분석 -> KoNLPy\n",
        "from nltk.tag import pos_tag\n",
        "emma_sentences = sent_tokenize(emma)\n",
        "# pos_tag(emma_sentences[1])\n",
        "list(filter(lambda r:r[1] == 'NN',\n",
        "            pos_tag(word_tokenize(emma_sentences[1]))))\n",
        "[('father', 'NN'),\n",
        " ('consequence', 'NN'),\n",
        " ('sister', 'NN'),\n",
        " ('marriage', 'NN'),\n",
        " ('mistress', 'NN'),\n",
        " ('house', 'NN'),\n",
        " ('period', 'NN')]\n",
        "upenn_tagset('PRP')\n",
        "PRP: pronoun, personal\n",
        "    hers herself him himself hisself it itself me myself one oneself ours\n",
        "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
        "brown_tagset('PRP')\n",
        "No matching tags found.\n",
        "뉴라인 분리, 문장 분리 달랐음\n",
        "len(word_tokenize(emma)), len(regexp_tokenize(emma, r'\\b\\w+\\b'))\n",
        "(191776, 161983)\n",
        "len(TweetTokenizer().tokenize(emma))\n",
        "193228"
      ]
    }
  ]
}