{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQFGBSNj8bkHMY8H0i2mIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunaeee/KU-SW-Academy/blob/main/0915.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQhtnAiBVncA"
      },
      "outputs": [],
      "source": [
        "HTTP response => Content-type: text/html\n",
        "HTML 파싱? 1. RE\n",
        "DOM(Document Object Model) => HTML Tags => Node => Tree\n",
        "                              --------- <- ----\n",
        "DOM 탐색; find_*(recursive=depth+-1/그 이상, limit=몇개)\n",
        "         find(자식/자손), find_parent(부모/조상)\n",
        "         ===> HTML 구조적 관계를 이용한 탐색 방법\n",
        "CSSOM 탐색; Selector(태그, #id, .class, [key=value])\n",
        "           => 가상선택자(Pseudo), :nth-child, :nth-of-type, ..., :has,:not\n",
        "           => 관계+속성(find_*(attrs={}))\n",
        "           => ( )로 자손, (>)로 자식\n",
        "e.g. dom.html.body...., dom.body\n",
        "     dom body True, dom > body False\n",
        "     dom a#id or dom a.class or dom a.classA.classB; a태그 classA and classB\n",
        "                                dom a.classA .classB; a태그 classA 자손 classB\n",
        "     select, select_one\n",
        "html = '''\n",
        "<div id=\"result1\">\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">링크1</a>\n",
        "<a class=\"blue\" href=\"/link2\">링크2</a>\n",
        "</p>\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">링크1</a>\n",
        "<a class=\"blue\" href=\"/link2\">링크2</a>\n",
        "</p>\n",
        "</div>\n",
        "<div id=\"result2\">\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">링크1</a>\n",
        "<a class=\"blue\" href=\"/link2\">링크2</a>\n",
        "</p>\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">링크1</a>\n",
        "<a class=\"blue\" href=\"/link2\">링크2</a>\n",
        "</p>\n",
        "</div>\n",
        "'''\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "dom = BeautifulSoup(html, 'html5lib')\n",
        "# id=result1 자식 p의 자식들 중에 a\n",
        "div = dom.find(attrs={'id':'result1'})\n",
        "p = div.find(recursive=False)\n",
        "p.find_all(recursive=False)\n",
        "[<a class=\"red\" href=\"/link1\">링크1</a>, <a class=\"blue\" href=\"/link2\">링크2</a>]\n",
        "div = dom.select_one('#result1')\n",
        "p = div.select_one('p')\n",
        "p.select('a')\n",
        "[<a class=\"red\" href=\"/link1\">링크1</a>, <a class=\"blue\" href=\"/link2\">링크2</a>]\n",
        "dom.select('#result1 > p > a')\n",
        "# id=result1\n",
        "# <p> 자식\n",
        "#  <a></a>\n",
        "#  <a></a>\n",
        "# </p>\n",
        "# <p> 자식\n",
        "#  <a></a>\n",
        "#  <a></a>\n",
        "# </p>\n",
        "[<a class=\"red\" href=\"/link1\">링크1</a>,\n",
        " <a class=\"blue\" href=\"/link2\">링크2</a>,\n",
        " <a class=\"red\" href=\"/link1\">링크1</a>,\n",
        " <a class=\"blue\" href=\"/link2\">링크2</a>]\n",
        "dom.select('#result1 > p:first-child > a')\n",
        "dom.select('#result1 > p:nth-child(1) > a')\n",
        "[<a class=\"red\" href=\"/link1\">링크1</a>, <a class=\"blue\" href=\"/link2\">링크2</a>]\n",
        "# +; next_sibling\n",
        "# p + p(*)\n",
        "# (*)p:has(+ p)\n",
        "dom.select('#result1 > p:has(+ p) > a')\n",
        "dom.select('#result1 > p + p > a')\n",
        "[<a class=\"red\" href=\"/link1\">링크1</a>, <a class=\"blue\" href=\"/link2\">링크2</a>]\n",
        "dom.select('#result1 > p:has(+ p) > a')[0]\\\n",
        " is dom.select('#result1 > p + p > a')[0]\n",
        "False\n",
        "<div id=\"result1\">\n",
        " <p id=\"p1\"> <----\n",
        " </p>\n",
        " <p id=\"p2\">\n",
        " </p>\n",
        "</div>\n",
        "<div id=\"result1\">\n",
        " <p id=\"p1\"> <---\n",
        " </p>\n",
        " <p> X\n",
        "</div>\n",
        "# id 위에처럼 중복 절대 X, id 대신 class라 생각\n",
        "#result1 > p:has(+ p + p) => #p1\n",
        "#result1 > p + p => #p2\n",
        "dom.find('article').find_all('a')\n",
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In [22], line 1\n",
        "----> 1 dom.find('article').find_all('a')\n",
        "\n",
        "AttributeError: 'NoneType' object has no attribute 'find_all'\n",
        "dom.select('article a')\n",
        "[]\n",
        "from requests import request\n",
        "from requests.exceptions import HTTPError\n",
        "from time import sleep\n",
        "\n",
        "def download(url, params={}, method='GET', retries=3):\n",
        "    resp = None\n",
        "\n",
        "    try:\n",
        "        resp = request(method, url,\n",
        "                       params=params if method=='GET' else {},\n",
        "                       data=params if method=='POST' else {},\n",
        "                       headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'})\n",
        "        resp.raise_for_status()\n",
        "        # 아니면,\n",
        "        # if resp.status_code != 200:\n",
        "    except HTTPError as e:\n",
        "        if 500 <= e.response.status_code:\n",
        "            if retries > 0:\n",
        "                sleep(3)\n",
        "                resp = download(url, params=params,\n",
        "                                method=method,\n",
        "                                retries=retries-1)\n",
        "            else:\n",
        "                print('재방문 횟수 초과')\n",
        "        else:\n",
        "            print('Request', resp.request.headers)\n",
        "            print('Response', e.response.headers)\n",
        "\n",
        "    return resp\n",
        "resp = download('http://pythonscraping.com/pages/page3.html')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "<table\n",
        " <tbody>\n",
        "    <tr>\n",
        "        <th>\n",
        "            <img>\n",
        "        </th>\n",
        "        <td>\n",
        "            <img>\n",
        " </tbody>\n",
        "</table>\n",
        "  Cell In [27], line 1\n",
        "    <table>\n",
        "    ^\n",
        "SyntaxError: invalid syntax\n",
        "table = dom.find('table')\n",
        "tbody = table.find('tbody')\n",
        "for tr in tbody.find_all('tr'):\n",
        "    print(type(tr.find_all(recursive=False)[-1]))\n",
        "    print(tr.find_all(recursive=False)[-1])\n",
        "<class 'bs4.element.Tag'>\n",
        "<th>\n",
        "Image\n",
        "</th>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img1.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img2.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img3.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img4.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img6.jpg\"/>\n",
        "</td>\n",
        "dom.select('table > tbody > tr > td > img')[0].find_parent()\n",
        "<td>\n",
        "<img src=\"../img/gifts/img1.jpg\"/>\n",
        "</td>\n",
        "dom.select('tr:has(td:has( > img[src$=jpg]))')\n",
        "[<tr class=\"gift\" id=\"gift1\"><td>\n",
        " Vegetable Basket\n",
        " </td><td>\n",
        " This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
        " <span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
        " </td><td>\n",
        " $15.00\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img1.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift2\"><td>\n",
        " Russian Nesting Dolls\n",
        " </td><td>\n",
        " Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
        " </td><td>\n",
        " $10,000.52\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img2.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift3\"><td>\n",
        " Fish Painting\n",
        " </td><td>\n",
        " If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
        " </td><td>\n",
        " $10,005.00\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img3.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift4\"><td>\n",
        " Dead Parrot\n",
        " </td><td>\n",
        " This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
        " </td><td>\n",
        " $0.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img4.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift5\"><td>\n",
        " Mystery Box\n",
        " </td><td>\n",
        " If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
        " </td><td>\n",
        " $1.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img6.jpg\"/>\n",
        " </td></tr>]\n",
        "dom.select('tbody > tr:nth-child(n)')\n",
        "dom.select('tbody > tr:nth-child(even|2n)')\n",
        "dom.select('tbody > tr:nth-child(odd|2n-1)')\n",
        "[<tr><th>\n",
        " Item Title\n",
        " </th><th>\n",
        " Description\n",
        " </th><th>\n",
        " Cost\n",
        " </th><th>\n",
        " Image\n",
        " </th></tr>,\n",
        " <tr class=\"gift\" id=\"gift2\"><td>\n",
        " Russian Nesting Dolls\n",
        " </td><td>\n",
        " Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
        " </td><td>\n",
        " $10,000.52\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img2.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift4\"><td>\n",
        " Dead Parrot\n",
        " </td><td>\n",
        " This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
        " </td><td>\n",
        " $0.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img4.jpg\"/>\n",
        " </td></tr>]\n",
        "resp = download('https://www.google.com/search', {'q':'카리나'})\n",
        "resp.status_code, resp.headers['content-type']\n",
        "(200, 'text/html; charset=UTF-8')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "import re\n",
        "dom.find(text=re.compile('나무위키')).find_parent().find_parent().find_parent().find_parent()\n",
        "<a data-ved=\"2ahUKEwjNjLKKsquBAxWqZ_EDHZGkD2AQFnoECE0QAQ\" href=\"https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)\" jsaction=\"rcuQ6b:npT2md\" jscontroller=\"M9mgyc\" jsname=\"UWckNb\" ping=\"/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https://namu.wiki/w/%25EC%25B9%25B4%25EB%25A6%25AC%25EB%2582%2598(aespa)&amp;ved=2ahUKEwjNjLKKsquBAxWqZ_EDHZGkD2AQFnoECE0QAQ\"><br/><h3 class=\"LC20lb MBeuO DKV0Md\">카리나(aespa)</h3><div class=\"notranslate TbwUpd NJjxre iUh30 ojE3Fb\"><span class=\"H9lube\"><div aria-hidden=\"true\" class=\"eqA2re NjwKYd Vwoesf\"><img alt=\"\" class=\"XNo5Ab\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAwFBMVEUBp5oCp5oDp5kFqJcGqJYHqZQKqpAOq40QrIsRrIoTrYgUrYcVroYXroMYr4MZr4Ebr4AcsH8dsH4esXsfsXohsnkisncjs3Yks3Ums3QntHMAn4YApYV6yLvp9vP0/Pue1spdvq/////b8OmR0cK34doApGdewKfS7OQAqns7uI4+tp3E5t4ArnOo3MWX1L4ArmuDzLhPvJpawJkAn2614cwAoXoytJVyx6uM0bau3NWl2sfE5+FCtaZPu6Rkv7KC2ANCAAABE0lEQVR4AdyRU4IDQQBEY9vJ9Oj1mLFx/1OtrQPsf7kymWwuXygWS6VSuVyp1uqNZqvd6fb6g+FoPJnOZv8LoIjynwBV0w3xB8BEk1iiUq03mz8BijaKo0lRdT3P9X9SMDADPOECuO2fMuhAKCKUGM9/AsRxPPrYwpK6EBGlPtETIE68dP5ph5CFCAGWjxaxRCeafwQIqYlqaGv6Y8jeCmu9YfxpSZWwWt3u2Lfbfnz4ASCItjsb5Lqb6vDZQlGPprDw4JRiQ7R6CJl8CHkGbB1t0Wj4cGoNPtcsXDg2PaLrtlarN0/4X4cq3LitE0Tl6awGB/8roAge8vXNfev71KHUo/vB0wPWuJCWZsORYEZIxgEAuatI9jt5CO8AAAAASUVORK5CYII=\" style=\"height:18px;width:18px\"/></div></span><div><span class=\"VuuXrf\">나무위키</span><div class=\"byrV5b\"><cite class=\"qLRx3b tjvcx GvPZzd cHaqb\" role=\"text\">https://namu.wiki<span class=\"dyjrff ob9lvb\" role=\"text\"> › 카리나(aespa)</span></cite></div></div></div></a>\n",
        "dom.select('h3')\n",
        "\n",
        "# H3\n",
        "len(dom.select('.LC20lb.MBeuO.DKV0Md'))\n",
        "len(dom.select('.LC20lb'))\n",
        "len(dom.select('h3.LC20lb'))\n",
        "len(dom.select('h3.LC20lb.MBeuO.DKV0Md'))\n",
        "\n",
        "len(dom.select('a[jsname=\"UWckNb\"] > h3'))\n",
        "len(dom.select('a > h3.LC20lb'))\n",
        "len(dom.select('a > h3.LC20lb.MBeuO.DKV0Md'))\n",
        "\n",
        "# A(자식으로 H3를 갖고 있는)\n",
        "len(dom.select('a[jsname=\"UWckNb\"]:has( > h3)'))\n",
        "len(dom.select('a:has( > h3.LC20lb)'))\n",
        "len(dom.select('a:has( > h3.LC20lb.MBeuO.DKV0Md)'))\n",
        "7\n",
        "for a in dom.select('a:has( > h3.LC20lb.MBeuO.DKV0Md)'):\n",
        "    print(a.attrs['href'])\n",
        "    print(a.select_one('h3').text)\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)\n",
        "카리나(aespa)\n",
        "https://www.instagram.com/karina_aespas_/\n",
        "AESPA KARINA 카리나 (@karina_aespas_)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98_(%EA%B0%80%EC%88%98)\n",
        "카리나 (가수) - 위키백과, 우리 모두의 백과사전\n",
        "https://www.youtube.com/shorts/Dul1Q0SK0n4\n",
        "Chicago #pinkchampagne #aespa #æspa #에스파 ... - YouTube\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)?rev=3170\n",
        "카리나(aespa) (r3170 판)\n",
        "https://www.youtube.com/watch?v=v63rTR68TdA\n",
        "230625 aespa(에스파) 'Next Level' 카리나 KARINA 4K Cam ...\n",
        "https://www.youtube.com/watch?v=gO_ONOnzH-s\n",
        "#PictureChallenge with #KARINA #GISELLE #HYO #효연 ...\n",
        "resp = download('https://search.daum.net/search', {'w':'tot',\n",
        "                                                   'q':'카리나'})\n",
        "resp.status_code, resp.headers['content-type']\n",
        "(200, 'text/html; charset=utf-8')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "# 뉴스의 링크\n",
        "dom.select('a.tit_main.fn_tit_u') # 속성만 이용(클래스)\n",
        "dom.select('.wrap_cont > a.tit_main') # 부모 관계와 속성 이용\n",
        "dom.select('.wrap_thumb[id] + .wrap_cont > a')\n",
        "for a in dom.select('#container > li > div:last-child > a'):\n",
        "    print(a.text.strip())\n",
        "    print(a.attrs['href'])\n",
        "에스파 카리나, 걸어 다니는 인형… 일상이 화보\n",
        "https://v.daum.net/v/20230903232408019?f=o\n",
        "카리나, 중단발 사진 공개…단발 욕구↑\n",
        "https://v.daum.net/v/20230911172827349?f=o\n",
        "에스파 카리나, 모자 커 보이는 착시 효과… ‘소두 인증’\n",
        "https://v.daum.net/v/20230911185502680?f=o\n",
        "카리나, 모자 커 보이는 착시효과..뉴욕시 '천사 강림' [스타IN★]\n",
        "https://v.daum.net/v/20230911183359250?f=o\n",
        "for title in dom.select('c-doc-web > c-title'):\n",
        "    print(title.text)\n",
        "    print(title.attrs['data-href'])\n",
        "카리나 (배우)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98%20%28%EB%B0%B0%EC%9A%B0%29\n",
        "카리나(가디언 테일즈) - 나무위키\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(%EA%B0%80%EB%94%94%EC%96%B8%20%ED%85%8C%EC%9D%BC%EC%A6%88)\n",
        "데뷔 이래 가장 짧은 머리인 카리나\n",
        "https://cafe.daum.net/subdued20club/ReHf/4523290?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "카리나 달글 8 100일동안 작성한📝 카푸🐱의 성장🌱일기를 볼 때는 👀 주위는 환하게💡 최대한 오래 🩵💙\n",
        "https://cafe.daum.net/Duckgu/D2nu/41411?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "고윤정 vs 카리나\n",
        "https://cafe.daum.net/ssaumjil/LnOm/3029160?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "손흥민이 월드컵 우승시키기 vs 카리나랑 결혼하기\n",
        "https://cafe.daum.net/dotax/Elgq/4240303?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "AI로 만든 에스파 카리나 바비.jpg\n",
        "https://table.cafe.daum.net/p/1217111531/207167064921750272\n",
        "에스파 윈터 가뿐하게 공주님 안기 성공하는 지젤 보고 호기롭게 도전하는 카리나\n",
        "https://table.cafe.daum.net/p/1000055110/176847531157393664\n",
        "최근 화제가 되고 있는 에스파 카리나 다이어트와 다이어트 식단\n",
        "https://nizniz.tistory.com/149\n",
        "시에나를 제대로 즐기는 방법 - 만지아의 탑, 캄포광장,시에나 대성당, 카타리나 그리고 카리나\n",
        "https://brunch.co.kr/@gle-bay/204\n",
        "원샷 카리나 - 카카오스토리\n",
        "http://story.kakao.com/_cOgo99/jKqXPaREfBa\n",
        "for a in dom.select('''\n",
        "#container > li > div:last-child > a,\n",
        "c-doc-web > c-title\n",
        "'''):\n",
        "    print(a.text.strip())\n",
        "    print(a.attrs[\n",
        "        ('' if a.has_attr('href') else 'data-') + 'href'])\n",
        "에스파 카리나, 걸어 다니는 인형… 일상이 화보\n",
        "https://v.daum.net/v/20230903232408019?f=o\n",
        "카리나, 중단발 사진 공개…단발 욕구↑\n",
        "https://v.daum.net/v/20230911172827349?f=o\n",
        "에스파 카리나, 모자 커 보이는 착시 효과… ‘소두 인증’\n",
        "https://v.daum.net/v/20230911185502680?f=o\n",
        "카리나, 모자 커 보이는 착시효과..뉴욕시 '천사 강림' [스타IN★]\n",
        "https://v.daum.net/v/20230911183359250?f=o\n",
        "카리나 (배우)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98%20%28%EB%B0%B0%EC%9A%B0%29\n",
        "카리나(가디언 테일즈) - 나무위키\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(%EA%B0%80%EB%94%94%EC%96%B8%20%ED%85%8C%EC%9D%BC%EC%A6%88)\n",
        "데뷔 이래 가장 짧은 머리인 카리나\n",
        "https://cafe.daum.net/subdued20club/ReHf/4523290?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "카리나 달글 8 100일동안 작성한📝 카푸🐱의 성장🌱일기를 볼 때는 👀 주위는 환하게💡 최대한 오래 🩵💙\n",
        "https://cafe.daum.net/Duckgu/D2nu/41411?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "고윤정 vs 카리나\n",
        "https://cafe.daum.net/ssaumjil/LnOm/3029160?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "손흥민이 월드컵 우승시키기 vs 카리나랑 결혼하기\n",
        "https://cafe.daum.net/dotax/Elgq/4240303?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "AI로 만든 에스파 카리나 바비.jpg\n",
        "https://table.cafe.daum.net/p/1217111531/207167064921750272\n",
        "에스파 윈터 가뿐하게 공주님 안기 성공하는 지젤 보고 호기롭게 도전하는 카리나\n",
        "https://table.cafe.daum.net/p/1000055110/176847531157393664\n",
        "최근 화제가 되고 있는 에스파 카리나 다이어트와 다이어트 식단\n",
        "https://nizniz.tistory.com/149\n",
        "시에나를 제대로 즐기는 방법 - 만지아의 탑, 캄포광장,시에나 대성당, 카타리나 그리고 카리나\n",
        "https://brunch.co.kr/@gle-bay/204\n",
        "원샷 카리나 - 카카오스토리\n",
        "http://story.kakao.com/_cOgo99/jKqXPaREfBa\n",
        "CSS Selector; 구조+속성\n",
        "Crawler = Crawling + Scraping(나중에)\n",
        "          => URL\n",
        "             => HyperLink = A[href/data-href/****]\n",
        "                            IMG[src], IFRAME[src], FROM[action]\n",
        "URLs = []\n",
        "seed = URLs 주소를 하나씩 꺼내서\n",
        "\n",
        "while URLs: # 종료 조건; 더이상 URL이 없을때까지\n",
        "    seed => /(루트)에 가서 robots.txt\n",
        "    seed => (HTTP) Req/Resp\n",
        "    Resp.status_code, Resp.Headers\n",
        "    content-type:text/html\n",
        "    HTML => DOM\n",
        "    온갖 링크 추출\n",
        "    링크를 절대주소의 형태로 변환\n",
        "    링크를 방문한적이 있는가?\n",
        "    URLs.append(새롭게 찾은 링크)\n",
        "AI: Search Space(탐색 -> Tree/Graph -> DFS, BFS, + Heuristic;Focused)\n",
        "ML: Data-driven Modeling\n",
        "DL: NN-based, Cost(Loss/Error) => Convex\n",
        "A:100, [A-1:200, A-1-1:, A-2:.. 500, 10, ...]\n",
        "                  Root:정보를 담고 있는 페이지\n",
        "         Node               Node\n",
        "Node         Node     Node         Node...\n",
        "Wiki\n",
        "BFS => Queue(FIFO/LILO)\n",
        "DFS => Stack(FILO/LIFO)\n",
        "     ================\n",
        "H => A, B, C, D <= T\n",
        "     ================\n",
        "pop, push => 자료구조 => 동적 => C\n",
        "from requests.compat import urljoin, urlparse\n",
        "\n",
        "url = 'https://www.google.com/search?q=%EC%B9%B4%EB%A6%AC%EB%82%98&oq=%EC%B9%B4%EB%A6%AC%EB%82%98&gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7Mg0IARAAGIMBGLEDGIAEMg0IAhAAGIMBGLEDGIAEMg0IAxAAGIMBGLEDGIAEMg0IBBAAGIMBGLEDGIAEMhMIBRAuGIMBGMcBGLEDGNEDGIAEMgYIBhBFGDwyBggHEEUYPNIBBzY2NWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8'\n",
        "\n",
        "URLs = []\n",
        "URLs.append((url, 0))\n",
        "# (url, depth) [0]:url, [1]:depth\n",
        "\n",
        "seens = []\n",
        "domain = ['www.google.com']\n",
        "\n",
        "# 전략; BFS(Queue)/DFS(Stack)\n",
        "#    ; Focused Crawling(depth, domain, content, ...)\n",
        "# 1. Depth\n",
        "# 2. Domain\n",
        "\n",
        "while URLs: # 종료 조건; 더이상 URL이 없을때까지\n",
        "    seed = URLs.pop(-1)\n",
        "    seens.append(seed[0])\n",
        "    # robots.txt 확인\n",
        "\n",
        "    resp = download(seed[0])\n",
        "\n",
        "    if resp.status_code != 200:\n",
        "        continue\n",
        "\n",
        "    if re.search('text/html', resp.headers['content-type']):\n",
        "        dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "        for link in dom.select('*[href], *[src], *[action]'):\n",
        "            if link.has_attr('src'):\n",
        "                href = link.attrs['src']\n",
        "            elif link.has_attr('href'):\n",
        "                href = link.attrs['href']\n",
        "            elif link.has_attr('action'):\n",
        "                href = link.attrs['action']\n",
        "\n",
        "            if not re.match('(?:#)|(?:javascript)|(?:data)', href):\n",
        "                # 링크를 절대주소의 형태로 변환\n",
        "                newurl = urljoin(resp.request.url, href)\n",
        "                # 링크를 방문할예정이거나 방문한적이 있는가?\n",
        "\n",
        "                # depth 제한\n",
        "                if seed[1] > 3:\n",
        "                    continue\n",
        "\n",
        "                # whitelist; opt-in\n",
        "                # blacklist; opt-out; in으로 바꾸면\n",
        "                if urlparse(newurl).netloc not in domain:\n",
        "                    continue\n",
        "\n",
        "                if newurl not in list(map(lambda r:r[0], seens)) and\\\n",
        "                   newurl not in list(map(lambda r:r[0], URLs)):\n",
        "                    # URLs.append(새롭게 찾은 링크)\n",
        "                    URLs.append((newurl, seed[1]+1))\n",
        "---------------------------------------------------------------------------\n",
        "KeyboardInterrupt                         Traceback (most recent call last)\n",
        "Cell In [126], line 22\n",
        "     19 seens.append(seed[0])\n",
        "     20 # robots.txt 확인\n",
        "---> 22 resp = download(seed[0])\n",
        "     24 if resp.status_code != 200:\n",
        "     25     continue\n",
        "\n",
        "Cell In [24], line 9, in download(url, params, method, retries)\n",
        "      6 resp = None\n",
        "      8 try:\n",
        "----> 9     resp = request(method, url,\n",
        "     10                    params=params if method=='GET' else {},\n",
        "     11                    data=params if method=='POST' else {},\n",
        "     12                    headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'})\n",
        "     13     resp.raise_for_status()\n",
        "     14     # 아니면,\n",
        "     15     # if resp.status_code != 200:\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/api.py:59, in request(method, url, **kwargs)\n",
        "     55 # By using the 'with' statement we are sure the session is closed, thus we\n",
        "     56 # avoid leaving sockets open which can trigger a ResourceWarning in some\n",
        "     57 # cases, and look like a memory leak in others.\n",
        "     58 with sessions.Session() as session:\n",
        "---> 59     return session.request(method=method, url=url, **kwargs)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/sessions.py:587, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
        "    582 send_kwargs = {\n",
        "    583     \"timeout\": timeout,\n",
        "    584     \"allow_redirects\": allow_redirects,\n",
        "    585 }\n",
        "    586 send_kwargs.update(settings)\n",
        "--> 587 resp = self.send(prep, **send_kwargs)\n",
        "    589 return resp\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/sessions.py:701, in Session.send(self, request, **kwargs)\n",
        "    698 start = preferred_clock()\n",
        "    700 # Send the request\n",
        "--> 701 r = adapter.send(request, **kwargs)\n",
        "    703 # Total elapsed time of the request (approximately)\n",
        "    704 elapsed = preferred_clock() - start\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/adapters.py:489, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)\n",
        "    487 try:\n",
        "    488     if not chunked:\n",
        "--> 489         resp = conn.urlopen(\n",
        "    490             method=request.method,\n",
        "    491             url=url,\n",
        "    492             body=request.body,\n",
        "    493             headers=request.headers,\n",
        "    494             redirect=False,\n",
        "    495             assert_same_host=False,\n",
        "    496             preload_content=False,\n",
        "    497             decode_content=False,\n",
        "    498             retries=self.max_retries,\n",
        "    499             timeout=timeout,\n",
        "    500         )\n",
        "    502     # Send the request.\n",
        "    503     else:\n",
        "    504         if hasattr(conn, \"proxy_pool\"):\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
        "    700     self._prepare_proxy(conn)\n",
        "    702 # Make the request on the httplib connection object.\n",
        "--> 703 httplib_response = self._make_request(\n",
        "    704     conn,\n",
        "    705     method,\n",
        "    706     url,\n",
        "    707     timeout=timeout_obj,\n",
        "    708     body=body,\n",
        "    709     headers=headers,\n",
        "    710     chunked=chunked,\n",
        "    711 )\n",
        "    713 # If we're going to release the connection in ``finally:``, then\n",
        "    714 # the response doesn't need to know about the connection. Otherwise\n",
        "    715 # it will also try to release it and we'll have a double-release\n",
        "    716 # mess.\n",
        "    717 response_conn = conn if not release_conn else None\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
        "    444             httplib_response = conn.getresponse()\n",
        "    445         except BaseException as e:\n",
        "    446             # Remove the TypeError from the exception chain in\n",
        "    447             # Python 3 (including for exceptions like SystemExit).\n",
        "    448             # Otherwise it looks like a bug in the code.\n",
        "--> 449             six.raise_from(e, None)\n",
        "    450 except (SocketTimeout, BaseSSLError, SocketError) as e:\n",
        "    451     self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
        "\n",
        "File <string>:3, in raise_from(value, from_value)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
        "    441 except TypeError:\n",
        "    442     # Python 3\n",
        "    443     try:\n",
        "--> 444         httplib_response = conn.getresponse()\n",
        "    445     except BaseException as e:\n",
        "    446         # Remove the TypeError from the exception chain in\n",
        "    447         # Python 3 (including for exceptions like SystemExit).\n",
        "    448         # Otherwise it looks like a bug in the code.\n",
        "    449         six.raise_from(e, None)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:1377, in HTTPConnection.getresponse(self)\n",
        "   1375 try:\n",
        "   1376     try:\n",
        "-> 1377         response.begin()\n",
        "   1378     except ConnectionError:\n",
        "   1379         self.close()\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:320, in HTTPResponse.begin(self)\n",
        "    318 # read until we get a non-100 response\n",
        "    319 while True:\n",
        "--> 320     version, status, reason = self._read_status()\n",
        "    321     if status != CONTINUE:\n",
        "    322         break\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:281, in HTTPResponse._read_status(self)\n",
        "    280 def _read_status(self):\n",
        "--> 281     line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
        "    282     if len(line) > _MAXLINE:\n",
        "    283         raise LineTooLong(\"status line\")\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/socket.py:704, in SocketIO.readinto(self, b)\n",
        "    702 while True:\n",
        "    703     try:\n",
        "--> 704         return self._sock.recv_into(b)\n",
        "    705     except timeout:\n",
        "    706         self._timeout_occurred = True\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/ssl.py:1242, in SSLSocket.recv_into(self, buffer, nbytes, flags)\n",
        "   1238     if flags != 0:\n",
        "   1239         raise ValueError(\n",
        "   1240           \"non-zero flags not allowed in calls to recv_into() on %s\" %\n",
        "   1241           self.__class__)\n",
        "-> 1242     return self.read(nbytes, buffer)\n",
        "   1243 else:\n",
        "   1244     return super().recv_into(buffer, nbytes, flags)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/ssl.py:1100, in SSLSocket.read(self, len, buffer)\n",
        "   1098 try:\n",
        "   1099     if buffer is not None:\n",
        "-> 1100         return self._sslobj.read(len, buffer)\n",
        "   1101     else:\n",
        "   1102         return self._sslobj.read(len)\n",
        "\n",
        "KeyboardInterrupt:\n",
        "len(URLs), len(seens)\n",
        "(1399, 41)\n",
        "list(map(lambda r:urlparse(r[0]).netloc, URLs))\n",
        "https://www.google.com/search?q=&oq=&gs_lcrp=&sourceid=&ie=UTF-8\n",
        "https://www.google.com/search?q=&oq=&gs_lcrp=&sourceid=&\n",
        "https://www.google.com/search?q=다른값&oq=&gs_lcrp=&sourceid=&\n",
        "    http or https\n",
        "    www.google.com; netloc; host; domain *\n",
        "    /search [dis]allow Y/N? 시점?"
      ]
    }
  ]
}