{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQFGBSNj8bkHMY8H0i2mIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunaeee/KU-SW-Academy/blob/main/0915.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQhtnAiBVncA"
      },
      "outputs": [],
      "source": [
        "HTTP response => Content-type: text/html\n",
        "HTML íŒŒì‹±? 1. RE\n",
        "DOM(Document Object Model) => HTML Tags => Node => Tree\n",
        "                              --------- <- ----\n",
        "DOM íƒìƒ‰; find_*(recursive=depth+-1/ê·¸ ì´ìƒ, limit=ëª‡ê°œ)\n",
        "         find(ìì‹/ìì†), find_parent(ë¶€ëª¨/ì¡°ìƒ)\n",
        "         ===> HTML êµ¬ì¡°ì  ê´€ê³„ë¥¼ ì´ìš©í•œ íƒìƒ‰ ë°©ë²•\n",
        "CSSOM íƒìƒ‰; Selector(íƒœê·¸, #id, .class, [key=value])\n",
        "           => ê°€ìƒì„ íƒì(Pseudo), :nth-child, :nth-of-type, ..., :has,:not\n",
        "           => ê´€ê³„+ì†ì„±(find_*(attrs={}))\n",
        "           => ( )ë¡œ ìì†, (>)ë¡œ ìì‹\n",
        "e.g. dom.html.body...., dom.body\n",
        "     dom body True, dom > body False\n",
        "     dom a#id or dom a.class or dom a.classA.classB; aíƒœê·¸ classA and classB\n",
        "                                dom a.classA .classB; aíƒœê·¸ classA ìì† classB\n",
        "     select, select_one\n",
        "html = '''\n",
        "<div id=\"result1\">\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">ë§í¬1</a>\n",
        "<a class=\"blue\" href=\"/link2\">ë§í¬2</a>\n",
        "</p>\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">ë§í¬1</a>\n",
        "<a class=\"blue\" href=\"/link2\">ë§í¬2</a>\n",
        "</p>\n",
        "</div>\n",
        "<div id=\"result2\">\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">ë§í¬1</a>\n",
        "<a class=\"blue\" href=\"/link2\">ë§í¬2</a>\n",
        "</p>\n",
        "<p class=row>\n",
        "<a class=\"red\" href=\"/link1\">ë§í¬1</a>\n",
        "<a class=\"blue\" href=\"/link2\">ë§í¬2</a>\n",
        "</p>\n",
        "</div>\n",
        "'''\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "dom = BeautifulSoup(html, 'html5lib')\n",
        "# id=result1 ìì‹ pì˜ ìì‹ë“¤ ì¤‘ì— a\n",
        "div = dom.find(attrs={'id':'result1'})\n",
        "p = div.find(recursive=False)\n",
        "p.find_all(recursive=False)\n",
        "[<a class=\"red\" href=\"/link1\">ë§í¬1</a>, <a class=\"blue\" href=\"/link2\">ë§í¬2</a>]\n",
        "div = dom.select_one('#result1')\n",
        "p = div.select_one('p')\n",
        "p.select('a')\n",
        "[<a class=\"red\" href=\"/link1\">ë§í¬1</a>, <a class=\"blue\" href=\"/link2\">ë§í¬2</a>]\n",
        "dom.select('#result1 > p > a')\n",
        "# id=result1\n",
        "# <p> ìì‹\n",
        "#  <a></a>\n",
        "#  <a></a>\n",
        "# </p>\n",
        "# <p> ìì‹\n",
        "#  <a></a>\n",
        "#  <a></a>\n",
        "# </p>\n",
        "[<a class=\"red\" href=\"/link1\">ë§í¬1</a>,\n",
        " <a class=\"blue\" href=\"/link2\">ë§í¬2</a>,\n",
        " <a class=\"red\" href=\"/link1\">ë§í¬1</a>,\n",
        " <a class=\"blue\" href=\"/link2\">ë§í¬2</a>]\n",
        "dom.select('#result1 > p:first-child > a')\n",
        "dom.select('#result1 > p:nth-child(1) > a')\n",
        "[<a class=\"red\" href=\"/link1\">ë§í¬1</a>, <a class=\"blue\" href=\"/link2\">ë§í¬2</a>]\n",
        "# +; next_sibling\n",
        "# p + p(*)\n",
        "# (*)p:has(+ p)\n",
        "dom.select('#result1 > p:has(+ p) > a')\n",
        "dom.select('#result1 > p + p > a')\n",
        "[<a class=\"red\" href=\"/link1\">ë§í¬1</a>, <a class=\"blue\" href=\"/link2\">ë§í¬2</a>]\n",
        "dom.select('#result1 > p:has(+ p) > a')[0]\\\n",
        " is dom.select('#result1 > p + p > a')[0]\n",
        "False\n",
        "<div id=\"result1\">\n",
        " <p id=\"p1\"> <----\n",
        " </p>\n",
        " <p id=\"p2\">\n",
        " </p>\n",
        "</div>\n",
        "<div id=\"result1\">\n",
        " <p id=\"p1\"> <---\n",
        " </p>\n",
        " <p> X\n",
        "</div>\n",
        "# id ìœ„ì—ì²˜ëŸ¼ ì¤‘ë³µ ì ˆëŒ€ X, id ëŒ€ì‹  classë¼ ìƒê°\n",
        "#result1 > p:has(+ p + p) => #p1\n",
        "#result1 > p + p => #p2\n",
        "dom.find('article').find_all('a')\n",
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In [22], line 1\n",
        "----> 1 dom.find('article').find_all('a')\n",
        "\n",
        "AttributeError: 'NoneType' object has no attribute 'find_all'\n",
        "dom.select('article a')\n",
        "[]\n",
        "from requests import request\n",
        "from requests.exceptions import HTTPError\n",
        "from time import sleep\n",
        "\n",
        "def download(url, params={}, method='GET', retries=3):\n",
        "    resp = None\n",
        "\n",
        "    try:\n",
        "        resp = request(method, url,\n",
        "                       params=params if method=='GET' else {},\n",
        "                       data=params if method=='POST' else {},\n",
        "                       headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'})\n",
        "        resp.raise_for_status()\n",
        "        # ì•„ë‹ˆë©´,\n",
        "        # if resp.status_code != 200:\n",
        "    except HTTPError as e:\n",
        "        if 500 <= e.response.status_code:\n",
        "            if retries > 0:\n",
        "                sleep(3)\n",
        "                resp = download(url, params=params,\n",
        "                                method=method,\n",
        "                                retries=retries-1)\n",
        "            else:\n",
        "                print('ì¬ë°©ë¬¸ íšŸìˆ˜ ì´ˆê³¼')\n",
        "        else:\n",
        "            print('Request', resp.request.headers)\n",
        "            print('Response', e.response.headers)\n",
        "\n",
        "    return resp\n",
        "resp = download('http://pythonscraping.com/pages/page3.html')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "<table\n",
        " <tbody>\n",
        "    <tr>\n",
        "        <th>\n",
        "            <img>\n",
        "        </th>\n",
        "        <td>\n",
        "            <img>\n",
        " </tbody>\n",
        "</table>\n",
        "  Cell In [27], line 1\n",
        "    <table>\n",
        "    ^\n",
        "SyntaxError: invalid syntax\n",
        "table = dom.find('table')\n",
        "tbody = table.find('tbody')\n",
        "for tr in tbody.find_all('tr'):\n",
        "    print(type(tr.find_all(recursive=False)[-1]))\n",
        "    print(tr.find_all(recursive=False)[-1])\n",
        "<class 'bs4.element.Tag'>\n",
        "<th>\n",
        "Image\n",
        "</th>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img1.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img2.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img3.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img4.jpg\"/>\n",
        "</td>\n",
        "<class 'bs4.element.Tag'>\n",
        "<td>\n",
        "<img src=\"../img/gifts/img6.jpg\"/>\n",
        "</td>\n",
        "dom.select('table > tbody > tr > td > img')[0].find_parent()\n",
        "<td>\n",
        "<img src=\"../img/gifts/img1.jpg\"/>\n",
        "</td>\n",
        "dom.select('tr:has(td:has( > img[src$=jpg]))')\n",
        "[<tr class=\"gift\" id=\"gift1\"><td>\n",
        " Vegetable Basket\n",
        " </td><td>\n",
        " This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
        " <span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
        " </td><td>\n",
        " $15.00\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img1.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift2\"><td>\n",
        " Russian Nesting Dolls\n",
        " </td><td>\n",
        " Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
        " </td><td>\n",
        " $10,000.52\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img2.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift3\"><td>\n",
        " Fish Painting\n",
        " </td><td>\n",
        " If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
        " </td><td>\n",
        " $10,005.00\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img3.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift4\"><td>\n",
        " Dead Parrot\n",
        " </td><td>\n",
        " This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
        " </td><td>\n",
        " $0.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img4.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift5\"><td>\n",
        " Mystery Box\n",
        " </td><td>\n",
        " If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
        " </td><td>\n",
        " $1.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img6.jpg\"/>\n",
        " </td></tr>]\n",
        "dom.select('tbody > tr:nth-child(n)')\n",
        "dom.select('tbody > tr:nth-child(even|2n)')\n",
        "dom.select('tbody > tr:nth-child(odd|2n-1)')\n",
        "[<tr><th>\n",
        " Item Title\n",
        " </th><th>\n",
        " Description\n",
        " </th><th>\n",
        " Cost\n",
        " </th><th>\n",
        " Image\n",
        " </th></tr>,\n",
        " <tr class=\"gift\" id=\"gift2\"><td>\n",
        " Russian Nesting Dolls\n",
        " </td><td>\n",
        " Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
        " </td><td>\n",
        " $10,000.52\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img2.jpg\"/>\n",
        " </td></tr>,\n",
        " <tr class=\"gift\" id=\"gift4\"><td>\n",
        " Dead Parrot\n",
        " </td><td>\n",
        " This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
        " </td><td>\n",
        " $0.50\n",
        " </td><td>\n",
        " <img src=\"../img/gifts/img4.jpg\"/>\n",
        " </td></tr>]\n",
        "resp = download('https://www.google.com/search', {'q':'ì¹´ë¦¬ë‚˜'})\n",
        "resp.status_code, resp.headers['content-type']\n",
        "(200, 'text/html; charset=UTF-8')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "import re\n",
        "dom.find(text=re.compile('ë‚˜ë¬´ìœ„í‚¤')).find_parent().find_parent().find_parent().find_parent()\n",
        "<a data-ved=\"2ahUKEwjNjLKKsquBAxWqZ_EDHZGkD2AQFnoECE0QAQ\" href=\"https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)\" jsaction=\"rcuQ6b:npT2md\" jscontroller=\"M9mgyc\" jsname=\"UWckNb\" ping=\"/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https://namu.wiki/w/%25EC%25B9%25B4%25EB%25A6%25AC%25EB%2582%2598(aespa)&amp;ved=2ahUKEwjNjLKKsquBAxWqZ_EDHZGkD2AQFnoECE0QAQ\"><br/><h3 class=\"LC20lb MBeuO DKV0Md\">ì¹´ë¦¬ë‚˜(aespa)</h3><div class=\"notranslate TbwUpd NJjxre iUh30 ojE3Fb\"><span class=\"H9lube\"><div aria-hidden=\"true\" class=\"eqA2re NjwKYd Vwoesf\"><img alt=\"\" class=\"XNo5Ab\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAwFBMVEUBp5oCp5oDp5kFqJcGqJYHqZQKqpAOq40QrIsRrIoTrYgUrYcVroYXroMYr4MZr4Ebr4AcsH8dsH4esXsfsXohsnkisncjs3Yks3Ums3QntHMAn4YApYV6yLvp9vP0/Pue1spdvq/////b8OmR0cK34doApGdewKfS7OQAqns7uI4+tp3E5t4ArnOo3MWX1L4ArmuDzLhPvJpawJkAn2614cwAoXoytJVyx6uM0bau3NWl2sfE5+FCtaZPu6Rkv7KC2ANCAAABE0lEQVR4AdyRU4IDQQBEY9vJ9Oj1mLFx/1OtrQPsf7kymWwuXygWS6VSuVyp1uqNZqvd6fb6g+FoPJnOZv8LoIjynwBV0w3xB8BEk1iiUq03mz8BijaKo0lRdT3P9X9SMDADPOECuO2fMuhAKCKUGM9/AsRxPPrYwpK6EBGlPtETIE68dP5ph5CFCAGWjxaxRCeafwQIqYlqaGv6Y8jeCmu9YfxpSZWwWt3u2Lfbfnz4ASCItjsb5Lqb6vDZQlGPprDw4JRiQ7R6CJl8CHkGbB1t0Wj4cGoNPtcsXDg2PaLrtlarN0/4X4cq3LitE0Tl6awGB/8roAge8vXNfev71KHUo/vB0wPWuJCWZsORYEZIxgEAuatI9jt5CO8AAAAASUVORK5CYII=\" style=\"height:18px;width:18px\"/></div></span><div><span class=\"VuuXrf\">ë‚˜ë¬´ìœ„í‚¤</span><div class=\"byrV5b\"><cite class=\"qLRx3b tjvcx GvPZzd cHaqb\" role=\"text\">https://namu.wiki<span class=\"dyjrff ob9lvb\" role=\"text\"> â€º ì¹´ë¦¬ë‚˜(aespa)</span></cite></div></div></div></a>\n",
        "dom.select('h3')\n",
        "\n",
        "# H3\n",
        "len(dom.select('.LC20lb.MBeuO.DKV0Md'))\n",
        "len(dom.select('.LC20lb'))\n",
        "len(dom.select('h3.LC20lb'))\n",
        "len(dom.select('h3.LC20lb.MBeuO.DKV0Md'))\n",
        "\n",
        "len(dom.select('a[jsname=\"UWckNb\"] > h3'))\n",
        "len(dom.select('a > h3.LC20lb'))\n",
        "len(dom.select('a > h3.LC20lb.MBeuO.DKV0Md'))\n",
        "\n",
        "# A(ìì‹ìœ¼ë¡œ H3ë¥¼ ê°–ê³  ìˆëŠ”)\n",
        "len(dom.select('a[jsname=\"UWckNb\"]:has( > h3)'))\n",
        "len(dom.select('a:has( > h3.LC20lb)'))\n",
        "len(dom.select('a:has( > h3.LC20lb.MBeuO.DKV0Md)'))\n",
        "7\n",
        "for a in dom.select('a:has( > h3.LC20lb.MBeuO.DKV0Md)'):\n",
        "    print(a.attrs['href'])\n",
        "    print(a.select_one('h3').text)\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)\n",
        "ì¹´ë¦¬ë‚˜(aespa)\n",
        "https://www.instagram.com/karina_aespas_/\n",
        "AESPA KARINA ì¹´ë¦¬ë‚˜ (@karina_aespas_)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98_(%EA%B0%80%EC%88%98)\n",
        "ì¹´ë¦¬ë‚˜ (ê°€ìˆ˜) - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „\n",
        "https://www.youtube.com/shorts/Dul1Q0SK0n4\n",
        "Chicago #pinkchampagne #aespa #Ã¦spa #ì—ìŠ¤íŒŒ ... - YouTube\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(aespa)?rev=3170\n",
        "ì¹´ë¦¬ë‚˜(aespa) (r3170 íŒ)\n",
        "https://www.youtube.com/watch?v=v63rTR68TdA\n",
        "230625 aespa(ì—ìŠ¤íŒŒ) 'Next Level' ì¹´ë¦¬ë‚˜ KARINA 4K Cam ...\n",
        "https://www.youtube.com/watch?v=gO_ONOnzH-s\n",
        "#PictureChallenge with #KARINA #GISELLE #HYO #íš¨ì—° ...\n",
        "resp = download('https://search.daum.net/search', {'w':'tot',\n",
        "                                                   'q':'ì¹´ë¦¬ë‚˜'})\n",
        "resp.status_code, resp.headers['content-type']\n",
        "(200, 'text/html; charset=utf-8')\n",
        "dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "# ë‰´ìŠ¤ì˜ ë§í¬\n",
        "dom.select('a.tit_main.fn_tit_u') # ì†ì„±ë§Œ ì´ìš©(í´ë˜ìŠ¤)\n",
        "dom.select('.wrap_cont > a.tit_main') # ë¶€ëª¨ ê´€ê³„ì™€ ì†ì„± ì´ìš©\n",
        "dom.select('.wrap_thumb[id] + .wrap_cont > a')\n",
        "for a in dom.select('#container > li > div:last-child > a'):\n",
        "    print(a.text.strip())\n",
        "    print(a.attrs['href'])\n",
        "ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜, ê±¸ì–´ ë‹¤ë‹ˆëŠ” ì¸í˜•â€¦ ì¼ìƒì´ í™”ë³´\n",
        "https://v.daum.net/v/20230903232408019?f=o\n",
        "ì¹´ë¦¬ë‚˜, ì¤‘ë‹¨ë°œ ì‚¬ì§„ ê³µê°œâ€¦ë‹¨ë°œ ìš•êµ¬â†‘\n",
        "https://v.daum.net/v/20230911172827349?f=o\n",
        "ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜, ëª¨ì ì»¤ ë³´ì´ëŠ” ì°©ì‹œ íš¨ê³¼â€¦ â€˜ì†Œë‘ ì¸ì¦â€™\n",
        "https://v.daum.net/v/20230911185502680?f=o\n",
        "ì¹´ë¦¬ë‚˜, ëª¨ì ì»¤ ë³´ì´ëŠ” ì°©ì‹œíš¨ê³¼..ë‰´ìš•ì‹œ 'ì²œì‚¬ ê°•ë¦¼' [ìŠ¤íƒ€INâ˜…]\n",
        "https://v.daum.net/v/20230911183359250?f=o\n",
        "for title in dom.select('c-doc-web > c-title'):\n",
        "    print(title.text)\n",
        "    print(title.attrs['data-href'])\n",
        "ì¹´ë¦¬ë‚˜ (ë°°ìš°)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98%20%28%EB%B0%B0%EC%9A%B0%29\n",
        "ì¹´ë¦¬ë‚˜(ê°€ë””ì–¸ í…Œì¼ì¦ˆ) - ë‚˜ë¬´ìœ„í‚¤\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(%EA%B0%80%EB%94%94%EC%96%B8%20%ED%85%8C%EC%9D%BC%EC%A6%88)\n",
        "ë°ë·” ì´ë˜ ê°€ì¥ ì§§ì€ ë¨¸ë¦¬ì¸ ì¹´ë¦¬ë‚˜\n",
        "https://cafe.daum.net/subdued20club/ReHf/4523290?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ì¹´ë¦¬ë‚˜ ë‹¬ê¸€ 8 100ì¼ë™ì•ˆ ì‘ì„±í•œğŸ“ ì¹´í‘¸ğŸ±ì˜ ì„±ì¥ğŸŒ±ì¼ê¸°ë¥¼ ë³¼ ë•ŒëŠ” ğŸ‘€ ì£¼ìœ„ëŠ” í™˜í•˜ê²ŒğŸ’¡ ìµœëŒ€í•œ ì˜¤ë˜ ğŸ©µğŸ’™\n",
        "https://cafe.daum.net/Duckgu/D2nu/41411?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ê³ ìœ¤ì • vs ì¹´ë¦¬ë‚˜\n",
        "https://cafe.daum.net/ssaumjil/LnOm/3029160?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ì†í¥ë¯¼ì´ ì›”ë“œì»µ ìš°ìŠ¹ì‹œí‚¤ê¸° vs ì¹´ë¦¬ë‚˜ë‘ ê²°í˜¼í•˜ê¸°\n",
        "https://cafe.daum.net/dotax/Elgq/4240303?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "AIë¡œ ë§Œë“  ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜ ë°”ë¹„.jpg\n",
        "https://table.cafe.daum.net/p/1217111531/207167064921750272\n",
        "ì—ìŠ¤íŒŒ ìœˆí„° ê°€ë¿í•˜ê²Œ ê³µì£¼ë‹˜ ì•ˆê¸° ì„±ê³µí•˜ëŠ” ì§€ì ¤ ë³´ê³  í˜¸ê¸°ë¡­ê²Œ ë„ì „í•˜ëŠ” ì¹´ë¦¬ë‚˜\n",
        "https://table.cafe.daum.net/p/1000055110/176847531157393664\n",
        "ìµœê·¼ í™”ì œê°€ ë˜ê³  ìˆëŠ” ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜ ë‹¤ì´ì–´íŠ¸ì™€ ë‹¤ì´ì–´íŠ¸ ì‹ë‹¨\n",
        "https://nizniz.tistory.com/149\n",
        "ì‹œì—ë‚˜ë¥¼ ì œëŒ€ë¡œ ì¦ê¸°ëŠ” ë°©ë²• - ë§Œì§€ì•„ì˜ íƒ‘, ìº„í¬ê´‘ì¥,ì‹œì—ë‚˜ ëŒ€ì„±ë‹¹, ì¹´íƒ€ë¦¬ë‚˜ ê·¸ë¦¬ê³  ì¹´ë¦¬ë‚˜\n",
        "https://brunch.co.kr/@gle-bay/204\n",
        "ì›ìƒ· ì¹´ë¦¬ë‚˜ - ì¹´ì¹´ì˜¤ìŠ¤í† ë¦¬\n",
        "http://story.kakao.com/_cOgo99/jKqXPaREfBa\n",
        "for a in dom.select('''\n",
        "#container > li > div:last-child > a,\n",
        "c-doc-web > c-title\n",
        "'''):\n",
        "    print(a.text.strip())\n",
        "    print(a.attrs[\n",
        "        ('' if a.has_attr('href') else 'data-') + 'href'])\n",
        "ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜, ê±¸ì–´ ë‹¤ë‹ˆëŠ” ì¸í˜•â€¦ ì¼ìƒì´ í™”ë³´\n",
        "https://v.daum.net/v/20230903232408019?f=o\n",
        "ì¹´ë¦¬ë‚˜, ì¤‘ë‹¨ë°œ ì‚¬ì§„ ê³µê°œâ€¦ë‹¨ë°œ ìš•êµ¬â†‘\n",
        "https://v.daum.net/v/20230911172827349?f=o\n",
        "ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜, ëª¨ì ì»¤ ë³´ì´ëŠ” ì°©ì‹œ íš¨ê³¼â€¦ â€˜ì†Œë‘ ì¸ì¦â€™\n",
        "https://v.daum.net/v/20230911185502680?f=o\n",
        "ì¹´ë¦¬ë‚˜, ëª¨ì ì»¤ ë³´ì´ëŠ” ì°©ì‹œíš¨ê³¼..ë‰´ìš•ì‹œ 'ì²œì‚¬ ê°•ë¦¼' [ìŠ¤íƒ€INâ˜…]\n",
        "https://v.daum.net/v/20230911183359250?f=o\n",
        "ì¹´ë¦¬ë‚˜ (ë°°ìš°)\n",
        "https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%A6%AC%EB%82%98%20%28%EB%B0%B0%EC%9A%B0%29\n",
        "ì¹´ë¦¬ë‚˜(ê°€ë””ì–¸ í…Œì¼ì¦ˆ) - ë‚˜ë¬´ìœ„í‚¤\n",
        "https://namu.wiki/w/%EC%B9%B4%EB%A6%AC%EB%82%98(%EA%B0%80%EB%94%94%EC%96%B8%20%ED%85%8C%EC%9D%BC%EC%A6%88)\n",
        "ë°ë·” ì´ë˜ ê°€ì¥ ì§§ì€ ë¨¸ë¦¬ì¸ ì¹´ë¦¬ë‚˜\n",
        "https://cafe.daum.net/subdued20club/ReHf/4523290?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ì¹´ë¦¬ë‚˜ ë‹¬ê¸€ 8 100ì¼ë™ì•ˆ ì‘ì„±í•œğŸ“ ì¹´í‘¸ğŸ±ì˜ ì„±ì¥ğŸŒ±ì¼ê¸°ë¥¼ ë³¼ ë•ŒëŠ” ğŸ‘€ ì£¼ìœ„ëŠ” í™˜í•˜ê²ŒğŸ’¡ ìµœëŒ€í•œ ì˜¤ë˜ ğŸ©µğŸ’™\n",
        "https://cafe.daum.net/Duckgu/D2nu/41411?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ê³ ìœ¤ì • vs ì¹´ë¦¬ë‚˜\n",
        "https://cafe.daum.net/ssaumjil/LnOm/3029160?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "ì†í¥ë¯¼ì´ ì›”ë“œì»µ ìš°ìŠ¹ì‹œí‚¤ê¸° vs ì¹´ë¦¬ë‚˜ë‘ ê²°í˜¼í•˜ê¸°\n",
        "https://cafe.daum.net/dotax/Elgq/4240303?q=%EC%B9%B4%EB%A6%AC%EB%82%98&re=1\n",
        "AIë¡œ ë§Œë“  ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜ ë°”ë¹„.jpg\n",
        "https://table.cafe.daum.net/p/1217111531/207167064921750272\n",
        "ì—ìŠ¤íŒŒ ìœˆí„° ê°€ë¿í•˜ê²Œ ê³µì£¼ë‹˜ ì•ˆê¸° ì„±ê³µí•˜ëŠ” ì§€ì ¤ ë³´ê³  í˜¸ê¸°ë¡­ê²Œ ë„ì „í•˜ëŠ” ì¹´ë¦¬ë‚˜\n",
        "https://table.cafe.daum.net/p/1000055110/176847531157393664\n",
        "ìµœê·¼ í™”ì œê°€ ë˜ê³  ìˆëŠ” ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜ ë‹¤ì´ì–´íŠ¸ì™€ ë‹¤ì´ì–´íŠ¸ ì‹ë‹¨\n",
        "https://nizniz.tistory.com/149\n",
        "ì‹œì—ë‚˜ë¥¼ ì œëŒ€ë¡œ ì¦ê¸°ëŠ” ë°©ë²• - ë§Œì§€ì•„ì˜ íƒ‘, ìº„í¬ê´‘ì¥,ì‹œì—ë‚˜ ëŒ€ì„±ë‹¹, ì¹´íƒ€ë¦¬ë‚˜ ê·¸ë¦¬ê³  ì¹´ë¦¬ë‚˜\n",
        "https://brunch.co.kr/@gle-bay/204\n",
        "ì›ìƒ· ì¹´ë¦¬ë‚˜ - ì¹´ì¹´ì˜¤ìŠ¤í† ë¦¬\n",
        "http://story.kakao.com/_cOgo99/jKqXPaREfBa\n",
        "CSS Selector; êµ¬ì¡°+ì†ì„±\n",
        "Crawler = Crawling + Scraping(ë‚˜ì¤‘ì—)\n",
        "          => URL\n",
        "             => HyperLink = A[href/data-href/****]\n",
        "                            IMG[src], IFRAME[src], FROM[action]\n",
        "URLs = []\n",
        "seed = URLs ì£¼ì†Œë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ\n",
        "\n",
        "while URLs: # ì¢…ë£Œ ì¡°ê±´; ë”ì´ìƒ URLì´ ì—†ì„ë•Œê¹Œì§€\n",
        "    seed => /(ë£¨íŠ¸)ì— ê°€ì„œ robots.txt\n",
        "    seed => (HTTP) Req/Resp\n",
        "    Resp.status_code, Resp.Headers\n",
        "    content-type:text/html\n",
        "    HTML => DOM\n",
        "    ì˜¨ê°– ë§í¬ ì¶”ì¶œ\n",
        "    ë§í¬ë¥¼ ì ˆëŒ€ì£¼ì†Œì˜ í˜•íƒœë¡œ ë³€í™˜\n",
        "    ë§í¬ë¥¼ ë°©ë¬¸í•œì ì´ ìˆëŠ”ê°€?\n",
        "    URLs.append(ìƒˆë¡­ê²Œ ì°¾ì€ ë§í¬)\n",
        "AI: Search Space(íƒìƒ‰ -> Tree/Graph -> DFS, BFS, + Heuristic;Focused)\n",
        "ML: Data-driven Modeling\n",
        "DL: NN-based, Cost(Loss/Error) => Convex\n",
        "A:100, [A-1:200, A-1-1:, A-2:.. 500, 10, ...]\n",
        "                  Root:ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” í˜ì´ì§€\n",
        "         Node               Node\n",
        "Node         Node     Node         Node...\n",
        "Wiki\n",
        "BFS => Queue(FIFO/LILO)\n",
        "DFS => Stack(FILO/LIFO)\n",
        "     ================\n",
        "H => A, B, C, D <= T\n",
        "     ================\n",
        "pop, push => ìë£Œêµ¬ì¡° => ë™ì  => C\n",
        "from requests.compat import urljoin, urlparse\n",
        "\n",
        "url = 'https://www.google.com/search?q=%EC%B9%B4%EB%A6%AC%EB%82%98&oq=%EC%B9%B4%EB%A6%AC%EB%82%98&gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7Mg0IARAAGIMBGLEDGIAEMg0IAhAAGIMBGLEDGIAEMg0IAxAAGIMBGLEDGIAEMg0IBBAAGIMBGLEDGIAEMhMIBRAuGIMBGMcBGLEDGNEDGIAEMgYIBhBFGDwyBggHEEUYPNIBBzY2NWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8'\n",
        "\n",
        "URLs = []\n",
        "URLs.append((url, 0))\n",
        "# (url, depth) [0]:url, [1]:depth\n",
        "\n",
        "seens = []\n",
        "domain = ['www.google.com']\n",
        "\n",
        "# ì „ëµ; BFS(Queue)/DFS(Stack)\n",
        "#    ; Focused Crawling(depth, domain, content, ...)\n",
        "# 1. Depth\n",
        "# 2. Domain\n",
        "\n",
        "while URLs: # ì¢…ë£Œ ì¡°ê±´; ë”ì´ìƒ URLì´ ì—†ì„ë•Œê¹Œì§€\n",
        "    seed = URLs.pop(-1)\n",
        "    seens.append(seed[0])\n",
        "    # robots.txt í™•ì¸\n",
        "\n",
        "    resp = download(seed[0])\n",
        "\n",
        "    if resp.status_code != 200:\n",
        "        continue\n",
        "\n",
        "    if re.search('text/html', resp.headers['content-type']):\n",
        "        dom = BeautifulSoup(resp.text, 'html5lib')\n",
        "        for link in dom.select('*[href], *[src], *[action]'):\n",
        "            if link.has_attr('src'):\n",
        "                href = link.attrs['src']\n",
        "            elif link.has_attr('href'):\n",
        "                href = link.attrs['href']\n",
        "            elif link.has_attr('action'):\n",
        "                href = link.attrs['action']\n",
        "\n",
        "            if not re.match('(?:#)|(?:javascript)|(?:data)', href):\n",
        "                # ë§í¬ë¥¼ ì ˆëŒ€ì£¼ì†Œì˜ í˜•íƒœë¡œ ë³€í™˜\n",
        "                newurl = urljoin(resp.request.url, href)\n",
        "                # ë§í¬ë¥¼ ë°©ë¬¸í• ì˜ˆì •ì´ê±°ë‚˜ ë°©ë¬¸í•œì ì´ ìˆëŠ”ê°€?\n",
        "\n",
        "                # depth ì œí•œ\n",
        "                if seed[1] > 3:\n",
        "                    continue\n",
        "\n",
        "                # whitelist; opt-in\n",
        "                # blacklist; opt-out; inìœ¼ë¡œ ë°”ê¾¸ë©´\n",
        "                if urlparse(newurl).netloc not in domain:\n",
        "                    continue\n",
        "\n",
        "                if newurl not in list(map(lambda r:r[0], seens)) and\\\n",
        "                   newurl not in list(map(lambda r:r[0], URLs)):\n",
        "                    # URLs.append(ìƒˆë¡­ê²Œ ì°¾ì€ ë§í¬)\n",
        "                    URLs.append((newurl, seed[1]+1))\n",
        "---------------------------------------------------------------------------\n",
        "KeyboardInterrupt                         Traceback (most recent call last)\n",
        "Cell In [126], line 22\n",
        "     19 seens.append(seed[0])\n",
        "     20 # robots.txt í™•ì¸\n",
        "---> 22 resp = download(seed[0])\n",
        "     24 if resp.status_code != 200:\n",
        "     25     continue\n",
        "\n",
        "Cell In [24], line 9, in download(url, params, method, retries)\n",
        "      6 resp = None\n",
        "      8 try:\n",
        "----> 9     resp = request(method, url,\n",
        "     10                    params=params if method=='GET' else {},\n",
        "     11                    data=params if method=='POST' else {},\n",
        "     12                    headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'})\n",
        "     13     resp.raise_for_status()\n",
        "     14     # ì•„ë‹ˆë©´,\n",
        "     15     # if resp.status_code != 200:\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/api.py:59, in request(method, url, **kwargs)\n",
        "     55 # By using the 'with' statement we are sure the session is closed, thus we\n",
        "     56 # avoid leaving sockets open which can trigger a ResourceWarning in some\n",
        "     57 # cases, and look like a memory leak in others.\n",
        "     58 with sessions.Session() as session:\n",
        "---> 59     return session.request(method=method, url=url, **kwargs)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/sessions.py:587, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
        "    582 send_kwargs = {\n",
        "    583     \"timeout\": timeout,\n",
        "    584     \"allow_redirects\": allow_redirects,\n",
        "    585 }\n",
        "    586 send_kwargs.update(settings)\n",
        "--> 587 resp = self.send(prep, **send_kwargs)\n",
        "    589 return resp\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/sessions.py:701, in Session.send(self, request, **kwargs)\n",
        "    698 start = preferred_clock()\n",
        "    700 # Send the request\n",
        "--> 701 r = adapter.send(request, **kwargs)\n",
        "    703 # Total elapsed time of the request (approximately)\n",
        "    704 elapsed = preferred_clock() - start\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/requests/adapters.py:489, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)\n",
        "    487 try:\n",
        "    488     if not chunked:\n",
        "--> 489         resp = conn.urlopen(\n",
        "    490             method=request.method,\n",
        "    491             url=url,\n",
        "    492             body=request.body,\n",
        "    493             headers=request.headers,\n",
        "    494             redirect=False,\n",
        "    495             assert_same_host=False,\n",
        "    496             preload_content=False,\n",
        "    497             decode_content=False,\n",
        "    498             retries=self.max_retries,\n",
        "    499             timeout=timeout,\n",
        "    500         )\n",
        "    502     # Send the request.\n",
        "    503     else:\n",
        "    504         if hasattr(conn, \"proxy_pool\"):\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
        "    700     self._prepare_proxy(conn)\n",
        "    702 # Make the request on the httplib connection object.\n",
        "--> 703 httplib_response = self._make_request(\n",
        "    704     conn,\n",
        "    705     method,\n",
        "    706     url,\n",
        "    707     timeout=timeout_obj,\n",
        "    708     body=body,\n",
        "    709     headers=headers,\n",
        "    710     chunked=chunked,\n",
        "    711 )\n",
        "    713 # If we're going to release the connection in ``finally:``, then\n",
        "    714 # the response doesn't need to know about the connection. Otherwise\n",
        "    715 # it will also try to release it and we'll have a double-release\n",
        "    716 # mess.\n",
        "    717 response_conn = conn if not release_conn else None\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
        "    444             httplib_response = conn.getresponse()\n",
        "    445         except BaseException as e:\n",
        "    446             # Remove the TypeError from the exception chain in\n",
        "    447             # Python 3 (including for exceptions like SystemExit).\n",
        "    448             # Otherwise it looks like a bug in the code.\n",
        "--> 449             six.raise_from(e, None)\n",
        "    450 except (SocketTimeout, BaseSSLError, SocketError) as e:\n",
        "    451     self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
        "\n",
        "File <string>:3, in raise_from(value, from_value)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
        "    441 except TypeError:\n",
        "    442     # Python 3\n",
        "    443     try:\n",
        "--> 444         httplib_response = conn.getresponse()\n",
        "    445     except BaseException as e:\n",
        "    446         # Remove the TypeError from the exception chain in\n",
        "    447         # Python 3 (including for exceptions like SystemExit).\n",
        "    448         # Otherwise it looks like a bug in the code.\n",
        "    449         six.raise_from(e, None)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:1377, in HTTPConnection.getresponse(self)\n",
        "   1375 try:\n",
        "   1376     try:\n",
        "-> 1377         response.begin()\n",
        "   1378     except ConnectionError:\n",
        "   1379         self.close()\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:320, in HTTPResponse.begin(self)\n",
        "    318 # read until we get a non-100 response\n",
        "    319 while True:\n",
        "--> 320     version, status, reason = self._read_status()\n",
        "    321     if status != CONTINUE:\n",
        "    322         break\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/http/client.py:281, in HTTPResponse._read_status(self)\n",
        "    280 def _read_status(self):\n",
        "--> 281     line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
        "    282     if len(line) > _MAXLINE:\n",
        "    283         raise LineTooLong(\"status line\")\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/socket.py:704, in SocketIO.readinto(self, b)\n",
        "    702 while True:\n",
        "    703     try:\n",
        "--> 704         return self._sock.recv_into(b)\n",
        "    705     except timeout:\n",
        "    706         self._timeout_occurred = True\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/ssl.py:1242, in SSLSocket.recv_into(self, buffer, nbytes, flags)\n",
        "   1238     if flags != 0:\n",
        "   1239         raise ValueError(\n",
        "   1240           \"non-zero flags not allowed in calls to recv_into() on %s\" %\n",
        "   1241           self.__class__)\n",
        "-> 1242     return self.read(nbytes, buffer)\n",
        "   1243 else:\n",
        "   1244     return super().recv_into(buffer, nbytes, flags)\n",
        "\n",
        "File /opt/homebrew/anaconda3/lib/python3.9/ssl.py:1100, in SSLSocket.read(self, len, buffer)\n",
        "   1098 try:\n",
        "   1099     if buffer is not None:\n",
        "-> 1100         return self._sslobj.read(len, buffer)\n",
        "   1101     else:\n",
        "   1102         return self._sslobj.read(len)\n",
        "\n",
        "KeyboardInterrupt:\n",
        "len(URLs), len(seens)\n",
        "(1399, 41)\n",
        "list(map(lambda r:urlparse(r[0]).netloc, URLs))\n",
        "https://www.google.com/search?q=&oq=&gs_lcrp=&sourceid=&ie=UTF-8\n",
        "https://www.google.com/search?q=&oq=&gs_lcrp=&sourceid=&\n",
        "https://www.google.com/search?q=ë‹¤ë¥¸ê°’&oq=&gs_lcrp=&sourceid=&\n",
        "    http or https\n",
        "    www.google.com; netloc; host; domain *\n",
        "    /search [dis]allow Y/N? ì‹œì ?"
      ]
    }
  ]
}